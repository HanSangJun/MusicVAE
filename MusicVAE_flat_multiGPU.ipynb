{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1, 2, 3'\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import sparse\n",
    "import random\n",
    "import librosa\n",
    "import mir_eval\n",
    "import fluidsynth\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from utils.drum_utils import *\n",
    "from utils.common_utils import *\n",
    "from utils.train import *\n",
    "from utils.test import *\n",
    "from utils.layers import *\n",
    "from utils.loss import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model with GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Lakh_9drum_4bar_4of4_16quant_round_big.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print('The number of data : %d' % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play example\n",
    "fs = 7\n",
    "pm = drum_play(data[814].todense(), fs)\n",
    "IPython.display.Audio(pm.fluidsynth(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split\n",
    "num_data = len(data)\n",
    "random.shuffle(data)\n",
    "\n",
    "num_train = int(num_data * 0.7)\n",
    "num_val = int(num_data * 0.1)\n",
    "\n",
    "train_data = data[:num_train]\n",
    "val_data = data[num_train:num_train+num_val]\n",
    "test_data = data[num_train+num_val:]\n",
    "\n",
    "print('The number of train: %d' % len(train_data))\n",
    "print('The number of validation: %d' % len(val_data))\n",
    "print('The number of test: %d' % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataloader\n",
    "class DatasetSampler(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx].todense().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "params = {'batch_size': 1024*4, \n",
    "          'shuffle': True,\n",
    "          'pin_memory': True,\n",
    "          'num_workers': 4}\n",
    "\n",
    "train_set = DataLoader(DatasetSampler(train_data), **params)\n",
    "val_set = DataLoader(DatasetSampler(val_data), **params)\n",
    "test_set = DataLoader(DatasetSampler(test_data), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "enc_input_size = 512\n",
    "enc_hidden_size = 1024\n",
    "enc_latent_dim = 512\n",
    "\n",
    "encoder = Encoder(enc_input_size, enc_hidden_size, enc_latent_dim)\n",
    "encoder = nn.DataParallel(encoder).to(device)\n",
    "\n",
    "dec_input_size = 512\n",
    "dec_hidden_size = 1024\n",
    "dec_output_size = 512\n",
    "\n",
    "decoder = Decoder(dec_input_size, dec_hidden_size, dec_output_size)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "model = [encoder, decoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init optimizer\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "optimizer = [enc_optimizer, dec_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = flat_train(device, vae_loss, train_set, val_set, model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model\n",
    "# path = '../model/Lakh_9drum_4bar_4of4_16quant_floor'\n",
    "# torch.save(encoder.state_dict(), path+'_encoder.pt')\n",
    "# torch.save(decoder.state_dict(), path+'_decoder.pt')\n",
    "\n",
    "# # load model\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, y_true, y_pred = flat_test(device, vae_loss, test_set, model, temp=1, options='full_sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "fs = 7; idx = 255\n",
    "pm = drum_play(y_true[idx], fs)\n",
    "IPython.display.Audio(pm.fluidsynth(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct sampled from categorical distribution\n",
    "pm = drum_play(prob_soft_label(y_pred[idx]), fs)\n",
    "IPython.display.Audio(pm.fluidsynth(fs=16000), rate=16000)\n",
    "# pm.write('output.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate custom inputs and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(z, decoder, seq_len=64, temp=1):\n",
    "    batch_size = z.shape[0]\n",
    "    \n",
    "    hidden_size = decoder.hidden_size\n",
    "    output_size = decoder.output_size\n",
    "    num_hidden = decoder.num_hidden\n",
    "    \n",
    "    h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
    "    c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
    "    \n",
    "    inputs = torch.zeros((batch_size, 1, output_size), device=device)\n",
    "    inputs = torch.cat((inputs, z.unsqueeze(1)), 2)\n",
    "    outputs = torch.zeros((batch_size, seq_len, output_size), device=device) # argmax\n",
    "    \n",
    "    # full sampling\n",
    "    for j in range(seq_len):\n",
    "        label, prob, h, c = decoder(inputs, h, c, temp=temp)\n",
    "        outputs[:, j, :] = prob.squeeze()\n",
    "\n",
    "        label = F.one_hot(label, num_classes=512)\n",
    "        inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom input\n",
    "sequence = [[0, 3], [3], [3], [0, 3], [3], [3], [1, 3], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new sample\n",
    "dim = 512\n",
    "hot_encoding = np.eye(dim)\n",
    "hot_encoded = np.zeros((2*len(sequence), dim), dtype='float32')\n",
    "\n",
    "for i in range(0, 2*len(sequence), 2):\n",
    "    hit_idx = int(i/2)\n",
    "    if sequence[hit_idx][0] == -1:\n",
    "        hot_encoded[i, 0] = 1\n",
    "        continue\n",
    "        \n",
    "    temp = np.zeros(9)\n",
    "    temp[sequence[hit_idx]] = 1\n",
    "    decimal = bin_to_dec(temp)\n",
    "    \n",
    "    hot_encoded[i, :] = hot_encoding[decimal]\n",
    "    hot_encoded[i+1, 0] = 1 # rest\n",
    "    \n",
    "hot_encoded = np.tile(hot_encoded, (4, 1))\n",
    "print('input shape :', hot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play input\n",
    "fs = 7\n",
    "pm = drum_play(hot_encoded, fs)\n",
    "IPython.display.Audio(pm.fluidsynth(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MusicVAE inference\n",
    "fs = 7\n",
    "temp = 2\n",
    "\n",
    "test = torch.from_numpy(hot_encoded).to(device).unsqueeze(0)\n",
    "\n",
    "z, mu, std = encoder(test)\n",
    "pred = np.squeeze(predict(z, decoder, temp=temp).data.cpu().numpy())\n",
    "\n",
    "pm = drum_play(prob_soft_label(pred), fs=fs)\n",
    "IPython.display.Audio(pm.fluidsynth(fs=16000), rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
